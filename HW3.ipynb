{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kdmalc/intro-computer-vision/blob/main/HW3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ELEC/COMP 447/546 Assignment 3"
      ],
      "metadata": {
        "id": "PlZ3bpkSZao2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## General instructions\n",
        "Please copy this colab notebook into your own Drive to edit. This notebook will also serve as your final submission report - please ensure that code cells run correctly, and that all non-code (text/latex) blocks are rendered correctly before submissing the file. Feel free to add any additional cells (code or text) you need. Please follow good coding, markdown, and presentation etiquette.\n",
        "\n",
        "__Please do not use any AI tools for this assignment.__\n",
        "\n",
        "\n",
        "## Submission instructions\n",
        "\n",
        "- Before submitting, please `run-all` the code. This will re-render your entire jupyter file cell by cell to produce all the outputs.\n",
        "\n",
        "- You are required to download the colab notebook as a `.ipynb` file and submit it to canvas. Please name your `.ipynb` file as `netid.ipynb`\n",
        "\n",
        "- Modify the text cell on top to include your name and the names of any collaborators from this class you worked with on this assignment.\n",
        "\n",
        "- Download a pdf of the executed colab notebook. You can use print -> save as pdf. Please name your `.pdf` file as `netid.pdf`.\n",
        "\n",
        "- Any extra images used in the homework should also be uploaded to canvas.\n",
        "\n",
        "- For simplicity, you can also upload a `netid.zip` file to canvas containing all solution files."
      ],
      "metadata": {
        "id": "t_52cwMJsAXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwIQ_WmZ7Uiv"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def min_max_normalize(x): return (x - x.min())/(x.max() - x.min()) # converts 0-255 uint8 image to 0-1 floating point image. Here, the max value of the image is mapped to 1 and min value is mapped to 0.\n",
        "\n",
        "def normalize_255(x): return x/255.0 # converts a 0-255 uint8 image to a floating 0-1 image by dividing by 255. Here, the images are consistently divided by 255.0 (max achievable value in an 8-bit image)\n",
        "\n",
        "def show_image(image, title=\"\", dpi=150, axis='off', cmap=None):\n",
        "    im = image.copy()\n",
        "    plt.figure(dpi=dpi)\n",
        "    plt.imshow(im, cmap=cmap)\n",
        "    plt.axis(axis)\n",
        "    plt.title(title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def show_image_subplot(images : list[np.ndarray], num_rows: int, num_cols: int,\n",
        "                       titles: list[str] = [], axis: str = 'off' , dpi: int = 80,\n",
        "                       cmap: str | None = None) -> None:\n",
        "    \"\"\" shows a matplotlib subplot for multiple images\"\"\"\n",
        "    assert num_rows > 1 or num_cols > 1 , \"Please ensure that you have more than 1 row or col\"\n",
        "    assert len(images) == int(num_rows*num_cols), \"Please ensure that number of images provided match rows x cols product\"\n",
        "    titles = titles + [\"No Title\" for _ in range(len(images)-len(titles))] if len(titles) < len(images) else titles[:len(images)]\n",
        "    fig, axs = plt.subplots(nrows=num_rows, ncols=num_cols, dpi=dpi)\n",
        "    axs_flat = axs.flatten()\n",
        "    for (_ax, _im, _title) in zip(axs_flat, images, titles):\n",
        "        _ax.imshow(_im, cmap=cmap)\n",
        "        _ax.axis(axis)\n",
        "        _ax.set_title(_title)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def gaussian2D(sigma: tuple[float, float], kernel_size: tuple[int, int]) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    sigma: a tuple of x, y scales (standard deviations)\n",
        "    kernel_size: a tuple of x, y dimensions of the kernel\n",
        "\n",
        "    returns a 2D gaussian blur kernel\n",
        "    \"\"\"\n",
        "    # Create the kernel: +/- x/2 on either side from center, same for +/- y/2\n",
        "    x = np.linspace(-(kernel_size[0]//2), kernel_size[0]//2, kernel_size[0])\n",
        "    y = np.linspace(-(kernel_size[1]//2), kernel_size[1]//2, kernel_size[1])\n",
        "    x, y = np.meshgrid(x, y)\n",
        "\n",
        "    # Compute the Gaussian function\n",
        "    kernel = (1 / (2 * np.pi * sigma[0] * sigma[1])) * np.exp(\n",
        "        -((x**2) / (2 * sigma[0]**2) + (y**2) / (2 * sigma[1]**2))\n",
        "    )\n",
        "    kernel /= np.sum(kernel)\n",
        "    return kernel\n",
        "\n",
        "\n",
        "# BASIC IMAGE PROCESSING FUNCTIONALITY FROM HW1!\n",
        "\n",
        "def read_image(filename, grayscale=True) -> np.ndarray:\n",
        "    if grayscale:\n",
        "      image = cv2.imread(filename, cv2.IMREAD_GRAYSCALE)\n",
        "    else:\n",
        "      image = cv2.imread(filename)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    print(f\"Initial image shape: {image.shape}\")\n",
        "    return image\n",
        "\n",
        "def resize_image(image :np.ndarray, size: tuple) -> np.ndarray :\n",
        "    resized_image = cv2.resize(image, size)\n",
        "    return resized_image\n",
        "\n",
        "from scipy.signal import convolve2d\n",
        "\n",
        "\n",
        "def blur(image, sigma):\n",
        "  ks_x = int(3*sigma[0] * 2)\n",
        "  ks_y = int(3*sigma[1] * 2)\n",
        "  kernel_size = (ks_x, ks_y)\n",
        "  my_kernel = gaussian2D(sigma, kernel_size)\n",
        "\n",
        "  image = min_max_normalize(image.astype(np.float32))\n",
        "\n",
        "  if len(image.shape)==3: # Process RGB channels\n",
        "      blurred_channels = []\n",
        "      # Process the 3 color channels separately, then stack them back together to form another image with len(shape)==3\n",
        "      for c in range(image.shape[2]):\n",
        "          channel = image[:, :, c]\n",
        "          blurred_ch = convolve2d(channel, my_kernel, mode=\"same\", boundary=\"symm\")\n",
        "          blurred_channels.append(min_max_normalize(blurred_ch))\n",
        "      blurred_image = np.stack(blurred_channels, axis=2)\n",
        "  else: # Process grayscale (eg 2D)\n",
        "      blurred_image = min_max_normalize(convolve2d(image, my_kernel, mode=\"same\", boundary=\"symm\"))\n",
        "      blurred_image = convolve2d(image, my_kernel, mode=\"same\", boundary=\"symm\")\n",
        "\n",
        "  return blurred_image\n",
        "\n",
        "\n",
        "def gausspyr(I: np.ndarray, n_levels: int, sigma: float):\n",
        "    I = min_max_normalize(I.astype(np.float32))\n",
        "    gaussian_pyramid_lst = [I]\n",
        "    for level in range(n_levels-1):\n",
        "      blurred_image = blur(gaussian_pyramid_lst[level], (sigma, sigma))\n",
        "      level_image = blurred_image[::2, ::2]\n",
        "      gaussian_pyramid_lst.append(level_image)\n",
        "    return gaussian_pyramid_lst\n"
      ],
      "metadata": {
        "id": "jSWBh9Ahi9HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.0 Implement the Lucas-Kanade algorithm"
      ],
      "metadata": {
        "id": "hyNAb4pt1jyU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem, you will implement the Lucas-Kanade algorithm and demonstrate tracking points\n",
        "on a video"
      ],
      "metadata": {
        "id": "UD8OuJFqD8u_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Some helper functions that are optional to use.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def read_video_into_numpy(filename):\n",
        "  cap = cv2.VideoCapture(filename)\n",
        "  frames = []\n",
        "  while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    # if frame is read correctly ret is True\n",
        "    if not ret:\n",
        "      print(\"Can't receive frame (stream end?). Exiting ...\")\n",
        "      break\n",
        "\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frames.append(frame)\n",
        "\n",
        "  cap.release()\n",
        "  video = np.stack(frames, axis=0)#converts to numpy array(T,H,W,C)\n",
        "  video = np.transpose(video, (1,2,3,0))#(T,H,W,C)->(H,W,C,T)\n",
        "  return frames"
      ],
      "metadata": {
        "id": "GoGCI0u5Piw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_corners(img):\n",
        "  dst = cv2.cornerHarris(img, 2, 3, 0.04)\n",
        "  y,x = np.where(dst > 0.1*dst.max()) # tuple of locations\n",
        "  return x, y"
      ],
      "metadata": {
        "id": "VHkm_NjmVvNX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Two options for calculating image derivatives\n",
        "\n",
        "def image_derivatives(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    # Sobel filters for x and y derivatives\n",
        "    sobel_x = np.array([[-1, 0, 1],\n",
        "                         [-2, 0, 2],\n",
        "                         [-1, 0, 1]])\n",
        "    sobel_y = np.array([[-1, -2, -1],\n",
        "                         [ 0,  0,  0],\n",
        "                         [ 1,  2,  1]])\n",
        "    # Compute derivatives using convolution\n",
        "    Ix = cv2.filter2D(image, -1, sobel_x)  # Convolve with Sobel X\n",
        "    Iy = cv2.filter2D(image, -1, sobel_y)  # Convolve with Sobel Y\n",
        "    return Ix, Iy\n",
        "\n",
        "def image_derivatives_numpy(image: np.ndarray) -> tuple[np.ndarray, np.ndarray]:\n",
        "    Ix, Iy = np.gradient(image)  # Solve directly\n",
        "    return Ix, Iy\n"
      ],
      "metadata": {
        "id": "GkRoFIDfmzrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code starts here ###\n",
        "\n",
        "# Read the video into frames\n",
        "frames = read_video_into_numpy('your video.mp4')\n",
        "\n",
        "\n",
        "# Implement Lucas-Kanade\n",
        "def lucas_kanade(imA, imB, points_matrix_A, L=5, sigma=3.0, K=10):\n",
        "  N = points_matrix_A.shape[0]\n",
        "  points_matrix_B = np.zeros_like(points_matrix_A)\n",
        "  # 1) Construct L-level Gaussian pyramids for A and B\n",
        "  gausspyrA = gausspyr(imA, L, sigma)\n",
        "  gausspyrB = gausspyr(imB, L, sigma)\n",
        "  # 2) Initialize flow guess for all points to 0\n",
        "  F = np.zeros_like(points_matrix_A)\n",
        "  for l in range(L-1, -1, -1):\n",
        "    # a) Calculate spatial derivatives (Ax, Ay) of A^l\n",
        "    # b) Location of points in this level:\n",
        "    # p_A^l = p_A/2^l\n",
        "    for i in range(N):\n",
        "      #p = px, py = p_A^l[i, :]\n",
        "      # G = big equation...\n",
        "      invG = np.linalg.inv(G)\n",
        "      # For K iterations,a pply LK refinement:\n",
        "      for k in range(1, K+1):\n",
        "        # b = big equation\n",
        "        F[i, :] += invG*b\n",
        "    if l<0:\n",
        "      F *= 2  # Optical flow guess for next level\n",
        "  points_matrix_B = points_matrix_A + F\n",
        "  return points_matrix_B"
      ],
      "metadata": {
        "id": "xXKAbxKjnC9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the gif\n",
        "import imageio\n",
        "imageio.mimsave('tracking.gif', im_list, fps=10)  # im_list is a list of your output images"
      ],
      "metadata": {
        "id": "7YOav_ADny09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.0 Image Compression with PCA"
      ],
      "metadata": {
        "id": "s451NjKwhFvz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this problem, you will use PCA to compress images, by encoding small patches in low-\n",
        "dimensional subspaces."
      ],
      "metadata": {
        "id": "ujS2IYq6owzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1 Use PCA to model patches"
      ],
      "metadata": {
        "id": "MwRR0myOqjbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Some helper functions that are optional to use.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Sample patches from the image\n",
        "def get_patches(img, patch_size=16, n_patches=1000, overlap=True):\n",
        "  h, w, c = img.shape\n",
        "  patches = np.zeros((n_patches, patch_size * patch_size * 3))\n",
        "  for i in range(n_patches):\n",
        "    x = np.random.randint(0, w - patch_size)\n",
        "    y = np.random.randint(0, h - patch_size)\n",
        "\n",
        "    patch = img[y:y+patch_size, x:x+patch_size, :].reshape((1, -1))\n",
        "\n",
        "    patches[i, :] = patch\n",
        "  if not overlap:\n",
        "    patches = []\n",
        "    for i in range(0, h, patch_size):\n",
        "      for j in range(0, w, patch_size):\n",
        "        if i<=h-patch_size and j<w-patch_size:\n",
        "          patch = img[i:i+patch_size, j:j+patch_size, :].reshape((-1,))\n",
        "          patches.append(patch)\n",
        "\n",
        "    patches = np.asarray(patches)\n",
        "\n",
        "  return patches"
      ],
      "metadata": {
        "id": "n0XWljvRbhSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code starts here ###\n",
        "\n",
        "# Load test image\n",
        "\n",
        "\n",
        "# Get patches from image\n",
        "\n",
        "\n",
        "# Implement PCA on the patches\n",
        "\n",
        "\n",
        "\n",
        "# Display the first 36 principal components\n"
      ],
      "metadata": {
        "id": "zBPNA3UMp30d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2 Compress the image"
      ],
      "metadata": {
        "id": "hI54FNlUpQlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Your code starts here ###\n",
        "\n",
        "# Image reconstruction\n",
        "\n"
      ],
      "metadata": {
        "id": "uqfywWQfq1G4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}